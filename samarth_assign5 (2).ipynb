{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJpegGxnEzEV",
        "outputId": "5f96c40d-d90e-44f2-855c-82392aa1f1a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.1.2\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9 (from pyspark==3.1.2)\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880745 sha256=fa0fd17cd7c5fc4ea1c23b36981d55ecf88af6b02c113be751a1eb31e1ea1e86\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/70/50/7882e1bcb5693225f7cc86698f10953201b48b3f36317c2d18\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.1.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.functions import col, sum as spark_sum\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"TaxiAnalysis\").getOrCreate()\n",
        "\n",
        "# Load data into DataFrame with appropriate column names\n",
        "column_names = [\"medallion\", \"hack_license\", \"pickup_datetime\", \"dropoff_datetime\",\n",
        "           \"trip_time_in_secs\", \"trip_distance\", \"pickup_longitude\", \"pickup_latitude\",\n",
        "           \"dropoff_longitude\", \"dropoff_latitude\", \"payment_type\", \"fare_amount\",\n",
        "           \"surcharge\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"total_amount\"]\n",
        "\n",
        "taxi_df = spark.read.csv('/taxi-data-sorted-small (1).csv', header=True, inferSchema=True)\n",
        "\n",
        "# Rename the columns using alias\n",
        "for old_col, new_col in zip(taxi_df.columns, column_names):\n",
        "    taxi_df = taxi_df.withColumnRenamed(old_col, new_col)\n",
        "\n",
        "\n",
        "cleaned_taxi_df = taxi_df.filter((col(\"trip_time_in_secs\").between(120, 3600)) &\n",
        "               (col(\"fare_amount\").between(3, 200)) &\n",
        "               (col(\"trip_distance\").between(1, 50)) &\n",
        "               (col(\"tolls_amount\") >= 3))\n",
        "#count\n",
        "n = cleaned_taxi_df.count()\n",
        "\n",
        "# Calculate sum of products (xy), sum of trip_distance, sum of fare_amount, and sum of squared trip_distance\n",
        "sum_xy = cleaned_taxi_df.select(spark_sum(col(\"trip_distance\") * col(\"fare_amount\"))).first()[0]\n",
        "sum_x = cleaned_taxi_df.agg(spark_sum(\"trip_distance\")).first()[0]\n",
        "sum_y = cleaned_taxi_df.agg(spark_sum(\"fare_amount\")).first()[0]\n",
        "sum_x_squared = cleaned_taxi_df.select(spark_sum(col(\"trip_distance\") ** 2)).first()[0]\n",
        "\n",
        "# Calculate slope (m) and y-intercept (b)\n",
        "m = (n * sum_xy - sum_x * sum_y) / (n * sum_x_squared - sum_x ** 2)\n",
        "b = (sum_y - m * sum_x) / n\n",
        "\n",
        "print(\"Slope (m):\", m)\n",
        "print(\"Y-intercept (b):\", b)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQMc6ZpUEzqj",
        "outputId": "9a97ca0d-9242-49ec-ff2b-225d81e3fe64"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (m): 2.3692447119543347\n",
            "Y-intercept (b): 8.645236596570763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task 2\n",
        "# Initial parameters\n",
        "m, b = 0.1, 0.1\n",
        "learning_rate = 0.0001\n",
        "num_iterations = 100\n",
        "#start_time = time.time()\n",
        "\n",
        "# Cost function\n",
        "def calculate_cost(data, m, b):\n",
        "    return data.select(spark_sum((col(\"fare_amount\") - (m * col(\"trip_distance\") + b)) ** 2)).first()[0]\n",
        "\n",
        "# Gradient Descent\n",
        "for i in range(num_iterations):\n",
        "    count = cleaned_taxi_df.count()\n",
        "\n",
        "    gradients = cleaned_taxi_df.withColumn(\n",
        "        \"gradient_x\",\n",
        "        (-2 / count) * col(\"trip_distance\") * (col(\"fare_amount\") - (m * col(\"trip_distance\") + b))\n",
        "    ).withColumn(\n",
        "        \"gradient_b\",\n",
        "        (-2 / count) * (col(\"fare_amount\") - (m * col(\"trip_distance\") + b))\n",
        "    )\n",
        "\n",
        "    # Update parameters\n",
        "    m = m - learning_rate * gradients.select(spark_sum(\"gradient_x\")).first()[0]\n",
        "    b = b - learning_rate * gradients.select(spark_sum(\"gradient_b\")).first()[0]\n",
        "\n",
        "    cost = calculate_cost(cleaned_taxi_df, m, b)\n",
        "    print(f\"Iteration {i + 1}, Cost: {cost}, Parameters: (m={m}, b={b})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqBD_TiHPRSA",
        "outputId": "78af24d9-bf67-416f-e485-e8bcd5faac38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, Cost: 59892252.86775915, Parameters: (m=0.20862494023752476, b=0.10755512445390783)\n",
            "Iteration 2, Cost: 55598767.582484365, Parameters: (m=0.3130872900306293, b=0.11482911704746726)\n",
            "Iteration 3, Cost: 51627992.361712664, Parameters: (m=0.41354654142778896, b=0.12183274929043918)\n",
            "Iteration 4, Cost: 47955671.32929683, Parameters: (m=0.5101560754484187, b=0.12857637997603277)\n",
            "Iteration 5, Cost: 44559371.75498222, Parameters: (m=0.6030633962304445, b=0.1350699709943762)\n",
            "Iteration 6, Cost: 41418347.02118597, Parameters: (m=0.6924103562063821, b=0.14132310254008523)\n",
            "Iteration 7, Cost: 38513409.88960439, Parameters: (m=0.7783333726516581, b=0.14734498773714513)\n",
            "Iteration 8, Cost: 35826815.29349564, Parameters: (m=0.860963635935766, b=0.15314448670343178)\n",
            "Iteration 9, Cost: 33342151.939649776, Parameters: (m=0.9404273097941548, b=0.15873012007634263)\n",
            "Iteration 10, Cost: 31044242.05788538, Parameters: (m=1.0168457239265882, b=0.16411008202018548)\n",
            "Iteration 11, Cost: 28919048.685687773, Parameters: (m=1.090335559215987, b=0.16929225273518161)\n",
            "Iteration 12, Cost: 26953589.921608064, Parameters: (m=1.1610090258505046, b=0.17428421048717935)\n",
            "Iteration 13, Cost: 25135859.623647783, Parameters: (m=1.2289740346207563, b=0.17909324317644215)\n",
            "Iteration 14, Cost: 23454754.06818923, Parameters: (m=1.2943343616536906, b=0.18372635946317226)\n",
            "Iteration 15, Cost: 21900004.121469967, Parameters: (m=1.357189806834598, b=0.1881902994667532)\n",
            "Iteration 16, Cost: 20462112.50925266, Parameters: (m=1.4176363461590795, b=0.19249154505504495)\n",
            "Iteration 17, Cost: 19132295.801502574, Parameters: (m=1.4757662782475696, b=0.19663632973943876)\n",
            "Iteration 18, Cost: 17902430.757670395, Parameters: (m=1.53166836524607, b=0.20063064819077717)\n",
            "Iteration 19, Cost: 16765004.704831779, Parameters: (m=1.585427968328189, b=0.20448026539066647)\n",
            "Iteration 20, Cost: 15713069.645554122, Parameters: (m=1.6371271780053427, b=0.20819072543215095)\n",
            "Iteration 21, Cost: 14740199.815158524, Parameters: (m=1.6868449394440503, b=0.21176735998318463)\n",
            "Iteration 22, Cost: 13840452.429108405, Parameters: (m=1.734657172981621, b=0.21521529642582007)\n",
            "Iteration 23, Cost: 13008331.380742725, Parameters: (m=1.780636890024216, b=0.21853946568353944)\n",
            "Iteration 24, Cost: 12238753.667600326, Parameters: (m=1.8248543045042083, b=0.22174460974867707)\n",
            "Iteration 25, Cost: 11527018.341243, Parameters: (m=1.8673769400669928, b=0.22483528892142457)\n",
            "Iteration 26, Cost: 10868777.790906634, Parameters: (m=1.9082697331508693, b=0.22781588877146897)\n",
            "Iteration 27, Cost: 10260011.185558997, Parameters: (m=1.9475951321173617, b=0.23069062683289207)\n",
            "Iteration 28, Cost: 9696999.912136396, Parameters: (m=1.9854131925833043, b=0.23346355904255076)\n",
            "Iteration 29, Cost: 9176304.85991427, Parameters: (m=2.0217816691002213, b=0.23613858593176715)\n",
            "Iteration 30, Cost: 8694745.412257617, Parameters: (m=2.056756103320963, b=0.23871945858078036)\n",
            "Iteration 31, Cost: 8249380.017412722, Parameters: (m=2.09038990878818, b=0.2412097843450505)\n",
            "Iteration 32, Cost: 7837488.219659433, Parameters: (m=2.1227344524740865, b=0.24361303236215556)\n",
            "Iteration 33, Cost: 7456554.041056575, Parameters: (m=2.153839133195977, b=0.24593253884768873)\n",
            "Iteration 34, Cost: 7104250.612266205, Parameters: (m=2.1837514570272045, b=0.24817151218824027)\n",
            "Iteration 35, Cost: 6778425.958571887, Parameters: (m=2.2125171098187497, b=0.2503330378392388)\n",
            "Iteration 36, Cost: 6477089.854264065, Parameters: (m=2.240180026942083, b=0.2524200830351292)\n",
            "Iteration 37, Cost: 6198401.6650891155, Parameters: (m=2.2667824603597855, b=0.25443550131907705)\n",
            "Iteration 38, Cost: 5940659.104497671, Parameters: (m=2.2923650431263267, b=0.2563820368991152)\n",
            "Iteration 39, Cost: 5702287.8350084, Parameters: (m=2.3169668514174515, b=0.25826232883738176)\n",
            "Iteration 40, Cost: 5481831.851163657, Parameters: (m=2.340625464182881, b=0.2600789150788453)\n",
            "Iteration 41, Cost: 5277944.5853325445, Parameters: (m=2.3633770205133837, b=0.261834236325667)\n",
            "Iteration 42, Cost: 5089380.682029305, Parameters: (m=2.3852562748097945, b=0.26353063976311447)\n",
            "Iteration 43, Cost: 4914988.390497882, Parameters: (m=2.4062966498382017, b=0.265170382642715)\n",
            "Iteration 44, Cost: 4753702.529094744, Parameters: (m=2.4265302877522936, b=0.2667556357281181)\n",
            "Iteration 45, Cost: 4604537.978489046, Parameters: (m=2.445988099160756, b=0.26828848660892834)\n",
            "Iteration 46, Cost: 4466583.66393411, Parameters: (m=2.464699810314621, b=0.26977094288756615)\n",
            "Iteration 47, Cost: 4338996.989849864, Parameters: (m=2.4826940084866127, b=0.2712049352440226)\n",
            "Iteration 48, Cost: 4220998.692719213, Parameters: (m=2.499998185611746, b=0.27259232038318654)\n",
            "Iteration 49, Cost: 4111868.080856146, Parameters: (m=2.516638780255824, b=0.2739348838692424)\n",
            "Iteration 50, Cost: 4010938.6319677318, Parameters: (m=2.5326412179758764, b=0.27523434285146764)\n",
            "Iteration 51, Cost: 3917593.9216167144, Parameters: (m=2.548029950134173, b=0.2764923486855885)\n",
            "Iteration 52, Cost: 3831263.857713391, Parameters: (m=2.5628284912250536, b=0.27771048945469773)\n",
            "Iteration 53, Cost: 3751421.1980345, Parameters: (m=2.577059454771556, b=0.27889029239358193)\n",
            "Iteration 54, Cost: 3677578.3294959487, Parameters: (m=2.59074458784665, b=0.28003322622015886)\n",
            "Iteration 55, Cost: 3609284.2895057355, Parameters: (m=2.6039048042717634, b=0.281140703377585)\n",
            "Iteration 56, Cost: 3546122.0112005435, Parameters: (m=2.6165602165432955, b=0.28221408219045513)\n",
            "Iteration 57, Cost: 3487705.775739058, Parameters: (m=2.6287301665358407, b=0.28325466893838586)\n",
            "Iteration 58, Cost: 3433678.856088876, Parameters: (m=2.640433255029006, b=0.28426371985014887)\n",
            "Iteration 59, Cost: 3383711.3379129223, Parameters: (m=2.6516873701028882, b=0.28524244302139773)\n",
            "Iteration 60, Cost: 3337498.1042457754, Parameters: (m=2.662509714445563, b=0.28619200025891567)\n",
            "Iteration 61, Cost: 3294756.9716470325, Parameters: (m=2.6729168316142733, b=0.28711350885420023)\n",
            "Iteration 62, Cost: 3255226.9664473347, Parameters: (m=2.682924631290403, b=0.2880080432890919)\n",
            "Iteration 63, Cost: 3218666.73055711, Parameters: (m=2.692548413566794, b=0.28887663687605053)\n",
            "Iteration 64, Cost: 3184853.047099558, Parameters: (m=2.7018028923044795, b=0.28972028333558375)\n",
            "Iteration 65, Cost: 3153579.4768617386, Parameters: (m=2.7107022175944904, b=0.2905399383132353)\n",
            "Iteration 66, Cost: 3124655.0972335306, Parameters: (m=2.7192599973590266, b=0.291336520838449)\n",
            "Iteration 67, Cost: 3097903.3359328504, Parameters: (m=2.7274893181249653, b=0.2921109147275356)\n",
            "Iteration 68, Cost: 3073160.8923906563, Parameters: (m=2.7354027650014205, b=0.292863969932884)\n",
            "Iteration 69, Cost: 3050276.7402085336, Parameters: (m=2.7430124408918526, b=0.293596503840477)\n",
            "Iteration 70, Cost: 3029111.204594522, Parameters: (m=2.750329984970052, b=0.29430930251769155)\n",
            "Iteration 71, Cost: 3009535.1091414383, Parameters: (m=2.7573665904482088, b=0.2950031219132892)\n",
            "Iteration 72, Cost: 2991428.986736228, Parameters: (m=2.764133021664185, b=0.295678689011428)\n",
            "Iteration 73, Cost: 2974682.3497799346, Parameters: (m=2.77063963051408, b=0.2963367029414579)\n",
            "Iteration 74, Cost: 2959193.0152595546, Parameters: (m=2.7768963722551736, b=0.2969778360451936)\n",
            "Iteration 75, Cost: 2944866.4805500265, Parameters: (m=2.7829128207033675, b=0.2976027349032943)\n",
            "Iteration 76, Cost: 2931615.34613309, Parameters: (m=2.7886981828483317, b=0.29821202132231717)\n",
            "Iteration 77, Cost: 2919358.781705573, Parameters: (m=2.79426131290866, b=0.2988062932839511)\n",
            "Iteration 78, Cost: 2908022.032417395, Parameters: (m=2.7996107258484964, b=0.29938612585788027)\n",
            "Iteration 79, Cost: 2897535.9622218534, Parameters: (m=2.804754610376263, b=0.2999520720796708)\n",
            "Iteration 80, Cost: 2887836.63154908, Parameters: (m=2.809700841445334, b=0.3005046637950203)\n",
            "Iteration 81, Cost: 2878864.906722923, Parameters: (m=2.8144569922757423, b=0.3010444124716601)\n",
            "Iteration 82, Cost: 2870566.098735407, Parameters: (m=2.819030345915261, b=0.3015718099801485)\n",
            "Iteration 83, Cost: 2862889.6291718166, Parameters: (m=2.8234279063575234, b=0.3020873293447477)\n",
            "Iteration 84, Cost: 2855788.7212457946, Parameters: (m=2.827656409234139, b=0.30259142546553053)\n",
            "Iteration 85, Cost: 2849220.114057509, Parameters: (m=2.831722332097141, b=0.30308453581281897)\n",
            "Iteration 86, Cost: 2843143.798328794, Parameters: (m=2.835631904307449, b=0.30356708109501507)\n",
            "Iteration 87, Cost: 2837522.772001168, Parameters: (m=2.839391116544457, b=0.3040394659008436)\n",
            "Iteration 88, Cost: 2832322.814204177, Parameters: (m=2.8430057299512512, b=0.3045020793169865)\n",
            "Iteration 89, Cost: 2827512.2762127994, Parameters: (m=2.8464812849294243, b=0.3049552955220527)\n",
            "Iteration 90, Cost: 2823061.888116981, Parameters: (m=2.8498231095969127, b=0.3053994743577895)\n",
            "Iteration 91, Cost: 2818944.580022656, Parameters: (m=2.8530363279217665, b=0.3058349618784075)\n",
            "Iteration 92, Cost: 2815135.3166920175, Parameters: (m=2.856125867544269, b=0.3062620908788578)\n",
            "Iteration 93, Cost: 2811610.944612162, Parameters: (m=2.8590964672993464, b=0.3066811814028685)\n",
            "Iteration 94, Cost: 2808350.0505592236, Parameters: (m=2.8619526844507552, b=0.3070925412315148)\n",
            "Iteration 95, Cost: 2805332.830792649, Parameters: (m=2.8646989016480826, b=0.30749646635306976)\n",
            "Iteration 96, Cost: 2802540.9700817876, Parameters: (m=2.867339333617191, b=0.307893241414852)\n",
            "Iteration 97, Cost: 2799957.5298246834, Parameters: (m=2.8698780335943095, b=0.30828314015776115)\n",
            "Iteration 98, Cost: 2797566.844576585, Parameters: (m=2.8723188995136026, b=0.3086664258341633)\n",
            "Iteration 99, Cost: 2795354.4263555184, Parameters: (m=2.874665679957658, b=0.3090433516097653)\n",
            "Iteration 100, Cost: 2793306.876140479, Parameters: (m=2.876921979879976, b=0.3094141609500909)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task 3\n",
        "import numpy as np\n",
        "\n",
        "def calculate_cost(X, y, m, b):\n",
        "    predictions = np.dot(X, m) + b  #vectorization\n",
        "    error = y - predictions.reshape(-1, 1)\n",
        "\n",
        "    cost = np.sum(error ** 2) / (2 * X.shape[0])\n",
        "    return cost\n",
        "\n",
        "def gradient_descent(X, y, m, b, learning_rate, beta):\n",
        "    num_samples = X.shape[0]\n",
        "    predictions = np.dot(X, m) + b\n",
        "    errors = y.flatten() - predictions\n",
        "\n",
        "    gradient_m = -2 * np.dot(X.T, errors) / num_samples\n",
        "    gradient_b = -2 * np.sum(errors) / num_samples\n",
        "\n",
        "    new_m = m - learning_rate * gradient_m\n",
        "    new_b = b - learning_rate * gradient_b\n",
        "\n",
        "    # Calculate new cost\n",
        "    new_cost = calculate_cost(X, y, new_m, new_b)\n",
        "\n",
        "    # Check if the new cost is lower, if not, decrease the learning rate\n",
        "    if new_cost > calculate_cost(X, y, m, b): #Bold driver\n",
        "        learning_rate /= beta\n",
        "\n",
        "    return new_m, new_b, learning_rate\n",
        "\n",
        "\n",
        "X = np.array(cleaned_taxi_df.select(\"trip_time_in_secs\", \"trip_distance\", \"fare_amount\", \"tolls_amount\").collect())\n",
        "y = np.array(cleaned_taxi_df.select(\"total_amount\").collect())\n",
        "\n",
        "# Add bias term to X\n",
        "X = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "m = np.ones(X.shape[1]) * 0.1\n",
        "b = 0.1\n",
        "learning_rate = 0.001\n",
        "max_iterations = 100\n",
        "beta = 1.5  # Bold Driver parameter\n",
        "\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Gradient Descent with Bold Driver\n",
        "for iteration in range(max_iterations):\n",
        "\n",
        "\n",
        "    # Calculate cost\n",
        "    cost = calculate_cost(X, y, m, b)\n",
        "\n",
        "    # Update parameters with Bold Driver\n",
        "    m, b, learning_rate = gradient_descent(X, y, m, b, learning_rate, beta)\n",
        "\n",
        "\n",
        "    print(f\"Iteration {iteration + 1}, Cost: {cost}\")\n",
        "    print(\"Model Parameters (m):\", m)\n",
        "    print(\"Model Parameter (b):\", b)\n",
        "    print(\"Learning Rate:\", learning_rate)\n",
        "    print()\n",
        "\n",
        "# Final model parameters\n",
        "print(\"Final Model Parameters (m):\", m)\n",
        "print(\"Final Model Parameter (b):\", b)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGbEP2kWFAOe",
        "outputId": "354df53e-3edd-40da-f9e1-ef872b70e81a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, Cost: 8834.457072136147\n",
            "Model Parameters (m): [-1.42930580e-01 -4.64875968e+02 -3.27844664e+00 -1.00505221e+01\n",
            " -1.13981603e+00]\n",
            "Model Parameter (b): -0.14293058005427406\n",
            "Learning Rate: 0.0006666666666666666\n",
            "\n",
            "Iteration 2, Cost: 334306302351.55817\n",
            "Model Parameters (m): [1.02142459e+03 1.91605607e+06 1.42024543e+04 4.29866256e+04\n",
            " 5.28391774e+03]\n",
            "Model Parameter (b): 1021.4245915370462\n",
            "Learning Rate: 0.0004444444444444444\n",
            "\n",
            "Iteration 3, Cost: 5.678758317474787e+18\n",
            "Model Parameters (m): [-2.80589281e+06 -5.26403383e+09 -3.90182487e+07 -1.18096933e+08\n",
            " -1.45162029e+07]\n",
            "Model Parameter (b): -2805892.8124737036\n",
            "Learning Rate: 0.0002962962962962963\n",
            "\n",
            "Iteration 4, Cost: 4.286218537701719e+25\n",
            "Model Parameters (m): [5.13820290e+09 9.63959590e+12 7.14509374e+10 2.16261284e+11\n",
            " 2.65823390e+10]\n",
            "Model Parameter (b): 5138202900.254034\n",
            "Learning Rate: 0.00019753086419753085\n",
            "\n",
            "Iteration 5, Cost: 1.4373238208853006e+32\n",
            "Model Parameters (m): [-6.27106858e+12 -1.17649241e+16 -8.72043665e+13 -2.63942349e+14\n",
            " -3.24431857e+13]\n",
            "Model Parameter (b): -6271068582946.056\n",
            "Learning Rate: 0.0001316872427983539\n",
            "\n",
            "Iteration 6, Cost: 2.140992885935863e+38\n",
            "Model Parameters (m): [5.10038119e+15 9.56863997e+18 7.09249955e+16 2.14669410e+17\n",
            " 2.63866695e+16]\n",
            "Model Parameter (b): 5100381193525995.0\n",
            "Learning Rate: 8.77914951989026e-05\n",
            "\n",
            "Iteration 7, Cost: 1.4162417559556675e+44\n",
            "Model Parameters (m): [-2.76379223e+18 -5.18505025e+21 -3.84328041e+19 -1.16324962e+20\n",
            " -1.42983964e+19]\n",
            "Model Parameter (b): -2.763792226186321e+18\n",
            "Learning Rate: 5.852766346593506e-05\n",
            "\n",
            "Iteration 8, Cost: 4.1585593619927313e+49\n",
            "Model Parameters (m): [9.97507047e+20 1.87138675e+24 1.38711559e+22 4.19839696e+22\n",
            " 5.16057286e+21]\n",
            "Model Parameter (b): 9.975070467632335e+20\n",
            "Learning Rate: 3.9018442310623374e-05\n",
            "\n",
            "Iteration 9, Cost: 5.417065266841288e+54\n",
            "Model Parameters (m): [-2.39680790e+23 -4.49656428e+26 -3.33295852e+24 -1.00878997e+25\n",
            " -1.23998140e+24]\n",
            "Model Parameter (b): -2.3968079023622405e+23\n",
            "Learning Rate: 2.6012294873748917e-05\n",
            "\n",
            "Iteration 10, Cost: 3.127509079689739e+59\n",
            "Model Parameters (m): [3.83137407e+25 7.18790179e+28 5.32784078e+26 1.61258302e+27\n",
            " 1.98214992e+26]\n",
            "Model Parameter (b): 3.831374074376208e+25\n",
            "Learning Rate: 1.734152991583261e-05\n",
            "\n",
            "Iteration 11, Cost: 7.991737966084601e+63\n",
            "Model Parameters (m): [-4.07027807e+27 -7.63610090e+30 -5.66005643e+28 -1.71313507e+29\n",
            " -2.10574618e+28]\n",
            "Model Parameter (b): -4.0702780686172174e+27\n",
            "Learning Rate: 1.1561019943888407e-05\n",
            "\n",
            "Iteration 12, Cost: 9.019454730333857e+67\n",
            "Model Parameters (m): [2.86915163e+29 5.38271120e+32 3.98979133e+30 1.20759423e+31\n",
            " 1.48434701e+30]\n",
            "Model Parameter (b): 2.8691516318399252e+29\n",
            "Learning Rate: 7.707346629258937e-06\n",
            "\n",
            "Iteration 13, Cost: 4.481662263604741e+71\n",
            "Model Parameters (m): [-1.33875208e+31 -2.51158417e+34 -1.86164488e+32 -5.63465962e+32\n",
            " -6.92599385e+31]\n",
            "Model Parameter (b): -1.3387520825988458e+31\n",
            "Learning Rate: 5.138231086172625e-06\n",
            "\n",
            "Iteration 14, Cost: 9.757362551999562e+74\n",
            "Model Parameters (m): [4.11980486e+32 7.72901631e+35 5.72892751e+33 1.73398035e+34\n",
            " 2.13136872e+33]\n",
            "Model Parameter (b): 4.1198048588637905e+32\n",
            "Learning Rate: 3.42548739078175e-06\n",
            "\n",
            "Iteration 15, Cost: 9.240286018344198e+77\n",
            "Model Parameters (m): [-8.31471957e+33 -1.55989435e+37 -1.15623014e+35 -3.49957361e+35\n",
            " -4.30159529e+34]\n",
            "Model Parameter (b): -8.314719568774084e+33\n",
            "Learning Rate: 2.2836582605211667e-06\n",
            "\n",
            "Iteration 16, Cost: 3.763806916702197e+80\n",
            "Model Parameters (m): [1.09101948e+35 2.04682204e+38 1.51715232e+36 4.59198047e+36\n",
            " 5.64435665e+35]\n",
            "Model Parameter (b): 1.0910194813122383e+35\n",
            "Learning Rate: 1.5224388403474445e-06\n",
            "\n",
            "Iteration 17, Cost: 6.480330180897925e+82\n",
            "Model Parameters (m): [-9.18023267e+35 -1.72227012e+39 -1.27658686e+37 -3.86385852e+37\n",
            " -4.74936591e+36]\n",
            "Model Parameter (b): -9.180232670318317e+35\n",
            "Learning Rate: 1.0149592268982964e-06\n",
            "\n",
            "Iteration 18, Cost: 4.588169992360231e+84\n",
            "Model Parameters (m): [4.84371220e+36 9.08711259e+39 6.73558020e+37 2.03866495e+38\n",
            " 2.50588001e+37]\n",
            "Model Parameter (b): 4.8437121973715945e+36\n",
            "Learning Rate: 6.766394845988642e-07\n",
            "\n",
            "Iteration 19, Cost: 1.2772878593959583e+86\n",
            "Model Parameters (m): [-1.54231586e+37 -2.89348278e+40 -2.14471705e+38 -6.49143705e+38\n",
            " -7.97912494e+37]\n",
            "Model Parameter (b): -1.5423158552133927e+37\n",
            "Learning Rate: 4.510929897325762e-07\n",
            "\n",
            "Iteration 20, Cost: 1.2950268410761669e+87\n",
            "Model Parameters (m): [2.75988252e+37 5.17771538e+40 3.83784364e+38 1.16160406e+39\n",
            " 1.42781696e+38]\n",
            "Model Parameter (b): 2.7598825164521523e+37\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 21, Cost: 4.146802139508227e+87\n",
            "Model Parameters (m): [-2.37246960e+37 -4.45090408e+40 -3.29911411e+38 -9.98546246e+38\n",
            " -1.22739005e+38]\n",
            "Model Parameter (b): -2.3724696011476675e+37\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 22, Cost: 3.0643152059744426e+87\n",
            "Model Parameters (m): [2.03943899e+37 3.82611744e+40 2.83600766e+38 8.58377340e+38\n",
            " 1.05509766e+38]\n",
            "Model Parameter (b): 2.039438988731289e+37\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 23, Cost: 2.2644021502987793e+87\n",
            "Model Parameters (m): [-1.75315687e+37 -3.28903396e+40 -2.43790883e+38 -7.37884361e+38\n",
            " -9.06990464e+37]\n",
            "Model Parameter (b): -1.7531568736411548e+37\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 24, Cost: 1.6732994987855095e+87\n",
            "Model Parameters (m): [1.50706103e+37 2.82734248e+40 2.09569232e+38 6.34305339e+38\n",
            " 7.79673515e+37]\n",
            "Model Parameter (b): 1.5070610303021758e+37\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 25, Cost: 1.2364990963580983e+87\n",
            "Model Parameters (m): [-1.29551039e+37 -2.43046001e+40 -1.80151375e+38 -5.45266012e+38\n",
            " -6.70228426e+37]\n",
            "Model Parameter (b): -1.2955103922547174e+37\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 26, Cost: 9.137216717055865e+86\n",
            "Model Parameters (m): [1.11365575e+37 2.08928911e+40 1.54862991e+38 4.68725401e+38\n",
            " 5.76146469e+37]\n",
            "Model Parameter (b): 1.1136557463130408e+37\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 27, Cost: 6.752025098954391e+86\n",
            "Model Parameters (m): [-9.57328578e+36 -1.79600939e+40 -1.33124413e+38 -4.02929023e+38\n",
            " -4.95271076e+37]\n",
            "Model Parameter (b): -9.573285777639254e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 28, Cost: 4.989467181161541e+86\n",
            "Model Parameters (m): [8.22945519e+36 1.54389821e+40 1.14437343e+38 3.46368678e+38\n",
            " 4.25748402e+37]\n",
            "Model Parameter (b): 8.229455187009816e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 29, Cost: 3.687009806249603e+86\n",
            "Model Parameters (m): [-7.07426209e+36 -1.32717663e+40 -9.83734329e+37 -2.97747876e+38\n",
            " -3.65984833e+37]\n",
            "Model Parameter (b): -7.07426209224356e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 30, Cost: 2.724547695735382e+86\n",
            "Model Parameters (m): [6.08122689e+36 1.14087690e+40 8.45644616e+37 2.55952122e+38\n",
            " 3.14610454e+37]\n",
            "Model Parameter (b): 6.081226887143338e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 31, Cost: 2.0133280182098528e+86\n",
            "Model Parameters (m): [-5.22758699e+36 -9.80728614e+39 -7.26938967e+37 -2.20023361e+38\n",
            " -2.70447649e+37]\n",
            "Model Parameter (b): -5.227586986554379e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 32, Cost: 1.487766103435666e+86\n",
            "Model Parameters (m): [4.49377506e+36 8.43060822e+39 6.24896382e+37 1.89138028e+38\n",
            " 2.32484108e+37]\n",
            "Model Parameter (b): 4.493775057101013e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 33, Cost: 1.0993975936917382e+86\n",
            "Model Parameters (m): [-3.86297049e+36 -7.24717868e+39 -5.37177819e+37 -1.62588160e+38\n",
            " -1.99849623e+37]\n",
            "Model Parameter (b): -3.8629704901595726e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 34, Cost: 8.124093338489235e+85\n",
            "Model Parameters (m): [3.32071384e+36 6.22987066e+39 4.61772571e+37 1.39765177e+38\n",
            " 1.71796137e+37]\n",
            "Model Parameter (b): 3.3207138359721813e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 35, Cost: 6.00336884046262e+85\n",
            "Model Parameters (m): [-2.85457536e+36 -5.35536519e+39 -3.96952182e+37 -1.20145923e+38\n",
            " -1.47680602e+37]\n",
            "Model Parameter (b): -2.8545753607208936e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 36, Cost: 4.436241182002613e+85\n",
            "Model Parameters (m): [2.45387013e+36 4.60361665e+39 3.41230824e+37 1.03280683e+38\n",
            " 1.26950237e+37]\n",
            "Model Parameter (b): 2.4538701293009893e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 37, Cost: 3.2781986827547464e+85\n",
            "Model Parameters (m): [-2.10941308e+36 -3.95739330e+39 -2.93331239e+37 -8.87828663e+37\n",
            " -1.09129855e+37]\n",
            "Model Parameter (b): -2.1094130827020646e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 38, Cost: 2.4224531901495564e+85\n",
            "Model Parameters (m): [1.81330850e+36 3.40188223e+39 2.52155461e+37 7.63201514e+37\n",
            " 9.38109726e+36]\n",
            "Model Parameter (b): 1.8133084959767386e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 39, Cost: 1.7900926778282892e+85\n",
            "Model Parameters (m): [-1.55876899e+36 -2.92434991e+39 -2.16759649e+37 -6.56068648e+37\n",
            " -8.06424474e+36]\n",
            "Model Parameter (b): -1.558768990548073e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 40, Cost: 1.3228044233195935e+85\n",
            "Model Parameters (m): [1.33995995e+36 2.51385022e+39 1.86332452e+37 5.63974341e+37\n",
            " 6.93224273e+36]\n",
            "Model Parameter (b): 1.3399599523705183e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 41, Cost: 9.77497737422577e+84\n",
            "Model Parameters (m): [-1.15186579e+36 -2.16097359e+39 -1.60176412e+37 -4.84807586e+37\n",
            " -5.95914320e+36]\n",
            "Model Parameter (b): -1.1518657895027756e+36\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 42, Cost: 7.223303837073737e+84\n",
            "Model Parameters (m): [9.90174964e+35 1.85763130e+39 1.37691973e+37 4.16753704e+37\n",
            " 5.12264055e+36]\n",
            "Model Parameter (b): 9.901749635766189e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 43, Cost: 5.337722669339427e+84\n",
            "Model Parameters (m): [-8.51181160e+35 -1.59687007e+39 -1.18363741e+37 -3.58252747e+37\n",
            " -4.40356026e+36]\n",
            "Model Parameter (b): -8.511811596664006e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 44, Cost: 3.944356202842842e+84\n",
            "Model Parameters (m): [7.31698329e+35 1.37271267e+39 1.01748671e+37 3.07963744e+37\n",
            " 3.78541942e+36]\n",
            "Model Parameter (b): 7.316983293117005e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 45, Cost: 2.9147160350371256e+84\n",
            "Model Parameters (m): [-6.28987659e+35 -1.18002091e+39 -8.74659074e+36 -2.64733957e+37\n",
            " -3.25404884e+36]\n",
            "Model Parameter (b): -6.289876591297118e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 46, Cost: 2.1538545526845584e+84\n",
            "Model Parameters (m): [5.40694791e+35 1.01437787e+39 7.51880579e+36 2.27572464e+37\n",
            " 2.79726833e+36]\n",
            "Model Parameter (b): 5.406947911344519e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 47, Cost: 1.591609398087007e+84\n",
            "Model Parameters (m): [-4.64795856e+35 -8.71986629e+38 -6.46336866e+36 -1.95627441e+37\n",
            " -2.40460745e+36]\n",
            "Model Parameter (b): -4.647958555526073e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 48, Cost: 1.1761334918931422e+84\n",
            "Model Parameters (m): [3.99551079e+35 7.49583273e+38 5.55608638e+36 1.68166635e+37\n",
            " 2.06706556e+36]\n",
            "Model Parameter (b): 3.9955107924736386e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 49, Cost: 8.691139876500912e+83\n",
            "Model Parameters (m): [-3.43464906e+35 -6.44362040e+38 -4.77616202e+36 -1.44560585e+37\n",
            " -1.77690542e+36]\n",
            "Model Parameter (b): -3.434649061918596e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 50, Cost: 6.422392770340978e+83\n",
            "Model Parameters (m): [2.95251716e+35 5.53911024e+38 4.10571795e+36 1.24268186e+37\n",
            " 1.52747592e+36]\n",
            "Model Parameter (b): 2.952517160241728e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 51, Cost: 4.745882528948081e+83\n",
            "Model Parameters (m): [-2.53806355e+35 -4.76156887e+38 -3.52938612e+36 -1.06824291e+37\n",
            " -1.31305958e+36]\n",
            "Model Parameter (b): -2.5380635471693917e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 52, Cost: 3.507010826648264e+83\n",
            "Model Parameters (m): [2.18178802e+35 4.09317329e+38 3.03395569e+36 9.18290475e+36\n",
            " 1.12874150e+36]\n",
            "Model Parameter (b): 2.181788020181536e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 53, Cost: 2.5915358973190894e+83\n",
            "Model Parameters (m): [-1.87552395e+35 -3.51860238e+38 -2.60807031e+36 -7.89387311e+36\n",
            " -9.70296704e+35]\n",
            "Model Parameter (b): -1.875523948251255e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 54, Cost: 1.9150378025813912e+83\n",
            "Model Parameters (m): [1.61225107e+35 3.02468570e+38 2.24196773e+36 6.78578667e+36\n",
            " 8.34093270e+35]\n",
            "Model Parameter (b): 1.6122510748153168e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 55, Cost: 1.415133700871942e+83\n",
            "Model Parameters (m): [-1.38593460e+35 -2.60010158e+38 -1.92725605e+36 -5.83324561e+36\n",
            " -7.17009118e+35]\n",
            "Model Parameter (b): -1.385934597415757e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 56, Cost: 1.0457252533835721e+83\n",
            "Model Parameters (m): [1.19138684e+35 2.23511759e+38 1.65672139e+36 5.01441558e+36\n",
            " 6.16360416e+35]\n",
            "Model Parameter (b): 1.1913868369433327e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 57, Cost: 7.727476950696131e+82\n",
            "Model Parameters (m): [-1.02414832e+35 -1.92136749e+38 -1.42416248e+36 -4.31052716e+36\n",
            " -5.29840071e+35]\n",
            "Model Parameter (b): -1.0241483240474636e+35\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 58, Cost: 5.710285739999928e+82\n",
            "Model Parameters (m): [8.80385579e+34 1.65165942e+38 1.22424856e+36 3.70544564e+36\n",
            " 4.55464845e+35]\n",
            "Model Parameter (b): 8.803855785339e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 59, Cost: 4.2196648971575655e+82\n",
            "Model Parameters (m): [-7.56803237e+34 -1.41981107e+38 -1.05239715e+36 -3.18530122e+36\n",
            " -3.91529891e+35]\n",
            "Model Parameter (b): -7.568032370386283e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 60, Cost: 3.118157769159866e+82\n",
            "Model Parameters (m): [6.50568516e+34 1.22050797e+38 9.04669031e+35 2.73817102e+36\n",
            " 3.36569676e+35]\n",
            "Model Parameter (b): 6.5056851633515995e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 61, Cost: 2.3041895767413937e+82\n",
            "Model Parameters (m): [-5.59246279e+34 -1.04918164e+38 -7.77677949e+35 -2.35380581e+36\n",
            " -2.89324389e+35]\n",
            "Model Parameter (b): -5.592462792183759e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 62, Cost: 1.702700760710434e+82\n",
            "Model Parameters (m): [4.80743216e+34 9.01904893e+37 6.68512983e+35 2.02339509e+36\n",
            " 2.48711065e+35]\n",
            "Model Parameter (b): 4.807432161168344e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 63, Cost: 1.2582254124350337e+82\n",
            "Model Parameters (m): [-4.13259861e+34 -7.75301821e+37 -5.74671827e+35 -1.73936510e+36\n",
            " -2.13798753e+35]\n",
            "Model Parameter (b): -4.1325986136473623e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 64, Cost: 9.297765203539135e+81\n",
            "Model Parameters (m): [3.55249346e+34 6.66470399e+37 4.94003434e+35 1.49520525e+36\n",
            " 1.83787186e+35]\n",
            "Model Parameter (b): 3.552493458257691e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 65, Cost: 6.870663787726204e+81\n",
            "Model Parameters (m): [-3.05381939e+34 -5.72915968e+37 -4.24658703e+35 -1.28531884e+36\n",
            " -1.57988432e+35]\n",
            "Model Parameter (b): -3.0538193880060223e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 66, Cost: 5.077136263454315e+81\n",
            "Model Parameters (m): [2.62514568e+34 4.92494050e+37 3.65048098e+35 1.10489482e+36\n",
            " 1.35811126e+35]\n",
            "Model Parameter (b): 2.625145680253734e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 67, Cost: 3.7517936307306263e+81\n",
            "Model Parameters (m): [-2.25664618e+34 -4.23361195e+37 -3.13805211e+35 -9.49797445e+35\n",
            " -1.16746915e+35]\n",
            "Model Parameter (b): -2.256646175055451e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 68, Cost: 2.7724202615776107e+81\n",
            "Model Parameters (m): [1.93987404e+34 3.63932726e+37 2.69755441e+35 8.16471554e+35\n",
            " 1.00358803e+35]\n",
            "Model Parameter (b): 1.939874041587854e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 69, Cost: 2.0487038636262015e+81\n",
            "Model Parameters (m): [-1.66756815e+34 -3.12846407e+37 -2.31889067e+35 -7.01861014e+35\n",
            " -8.62711396e+34]\n",
            "Model Parameter (b): -1.6675681539542297e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 70, Cost: 1.5139073895126633e+81\n",
            "Model Parameters (m): [1.43348665e+34 2.68931226e+37 1.99338110e+35 6.03338697e+35\n",
            " 7.41610032e+34]\n",
            "Model Parameter (b): 1.433486653923415e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 71, Cost: 1.1187149224995098e+81\n",
            "Model Parameters (m): [-1.23226387e+34 -2.31180550e+37 -1.71356426e+35 -5.18646250e+35\n",
            " -6.37508026e+34]\n",
            "Model Parameter (b): -1.2322638696316995e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 72, Cost: 8.2668404057791e+80\n",
            "Model Parameters (m): [1.05928733e+34 1.98729049e+37 1.47302615e+35 4.45842334e+35\n",
            " 5.48019129e+34]\n",
            "Model Parameter (b): 1.0592873263620835e+34\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 73, Cost: 6.108853016989451e+80\n",
            "Model Parameters (m): [-9.10592014e+33 -1.70832862e+37 -1.26625309e+35 -3.83258119e+35\n",
            " -4.71092054e+34]\n",
            "Model Parameter (b): -9.105920143563725e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 74, Cost: 4.5141896240180154e+80\n",
            "Model Parameters (m): [7.82769506e+33 1.46852545e+37 1.08850538e+35 3.29459038e+35\n",
            " 4.04963462e+34]\n",
            "Model Parameter (b): 7.827695058982394e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 75, Cost: 3.3357993562651044e+80\n",
            "Model Parameters (m): [-6.72889823e+33 -1.26238417e+37 -9.35708643e+34 -2.83211893e+35\n",
            " -3.48117537e+34]\n",
            "Model Parameter (b): -6.72889822572716e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 76, Cost: 2.465017704629418e+80\n",
            "Model Parameters (m): [5.78434278e+33 1.08517955e+37 8.04360439e+34 2.43456597e+35\n",
            " 2.99251243e+34]\n",
            "Model Parameter (b): 5.784342775791996e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 77, Cost: 1.821546092910009e+80\n",
            "Model Parameters (m): [-4.97237738e+33 -9.32849666e+36 -6.91449972e+34 -2.09281871e+35\n",
            " -2.57244456e+34]\n",
            "Model Parameter (b): -4.972377378406325e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 78, Cost: 1.3460471956709778e+80\n",
            "Model Parameters (m): [4.27438998e+33 8.01902785e+36 5.94389084e+34 1.79904352e+35\n",
            " 2.21134287e+34]\n",
            "Model Parameter (b): 4.274389982798186e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 79, Cost: 9.946731845139445e+79\n",
            "Model Parameters (m): [-3.67438115e+33 -6.89337307e+36 -5.10952920e+34 -1.54650643e+35\n",
            " -1.90093009e+34]\n",
            "Model Parameter (b): -3.674381148787779e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 80, Cost: 7.350223284688791e+79\n",
            "Model Parameters (m): [3.15859734e+33 5.92572979e+36 4.39228940e+34 1.32941873e+35\n",
            " 1.63409089e+34]\n",
            "Model Parameter (b): 3.15859734350348e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 81, Cost: 5.4315108897986674e+79\n",
            "Model Parameters (m): [-2.71521564e+33 -5.09391748e+36 -3.77573067e+34 -1.14280427e+35\n",
            " -1.40470869e+34]\n",
            "Model Parameter (b): -2.715215640064169e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 82, Cost: 4.013661817247971e+79\n",
            "Model Parameters (m): [2.33407275e+33 4.37886914e+36 3.24572013e+34 9.82385435e+34\n",
            " 1.20752555e+34]\n",
            "Model Parameter (b): 2.3340727493036965e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 83, Cost: 2.9659300165430185e+79\n",
            "Model Parameters (m): [-2.00643202e+33 -3.76419426e+36 -2.79010874e+34 -8.44485070e+34\n",
            " -1.03802160e+34]\n",
            "Model Parameter (b): -2.006432014864188e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 84, Cost: 2.1916995660243466e+79\n",
            "Model Parameters (m): [1.72478319e+33 3.23580312e+36 2.39845289e+34 7.25942190e+34\n",
            " 8.92311423e+33]\n",
            "Model Parameter (b): 1.724783189130412e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 85, Cost: 1.619575297096893e+79\n",
            "Model Parameters (m): [-1.48267024e+33 -2.78158381e+36 -2.06177492e+34 -6.24039525e+34\n",
            " -7.67055014e+33]\n",
            "Model Parameter (b): -1.4826702419662092e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 86, Cost: 1.1967991341644098e+79\n",
            "Model Parameters (m): [1.27454341e+33 2.39112462e+36 1.77235745e+34 5.36441243e+34\n",
            " 6.59381222e+33]\n",
            "Model Parameter (b): 1.274543413691732e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 87, Cost: 8.84385042241698e+78\n",
            "Model Parameters (m): [-1.09563196e+33 -2.05547535e+36 -1.52356636e+34 -4.61139389e+34\n",
            " -5.66821918e+33]\n",
            "Model Parameter (b): -1.0956319625874438e+33\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 88, Cost: 6.535239545330616e+78\n",
            "Model Parameters (m): [9.41834848e+32 1.76694216e+36 1.30969882e+34 3.96407883e+34\n",
            " 4.87255442e+33]\n",
            "Model Parameter (b): 9.41834848441734e+32\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 89, Cost: 4.829271626597934e+78\n",
            "Model Parameters (m): [-8.09626688e+32 -1.51891124e+36 -1.12585250e+34 -3.40762929e+34\n",
            " -4.18857945e+33]\n",
            "Model Parameter (b): -8.096266879459105e+32\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 90, Cost: 3.568631919563805e+78\n",
            "Model Parameters (m): [6.95976984e+32 1.30569715e+36 9.67813241e+33 2.92929024e+34\n",
            " 3.60061611e+33]\n",
            "Model Parameter (b): 6.95976984633775e+32\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 91, Cost: 2.637071335393359e+78\n",
            "Model Parameters (m): [-5.98280624e+32 -1.12241256e+36 -8.31958414e+33 -2.51809705e+34\n",
            " -3.09518690e+33]\n",
            "Model Parameter (b): -5.9828062353570156e+32\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 92, Cost: 1.948686607276502e+78\n",
            "Model Parameters (m): [5.14298195e+32 9.64856170e+35 7.15173942e+33 2.16462429e+34\n",
            " 2.66070633e+33]\n",
            "Model Parameter (b): 5.14298195718966e+32\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 93, Cost: 1.4399987753127217e+78\n",
            "Model Parameters (m): [-4.42104627e+32 -8.29416440e+35 -6.14782845e+33 -1.86076953e+34\n",
            " -2.28721505e+33]\n",
            "Model Parameter (b): -4.421046264403337e+32\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 94, Cost: 1.0640995145957562e+78\n",
            "Model Parameters (m): [3.80045087e+32 7.12988788e+35 5.28483954e+33 1.59956779e+34\n",
            " 1.96615190e+33]\n",
            "Model Parameter (b): 3.800450877226303e+32\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 95, Cost: 7.863255138651223e+77\n",
            "Model Parameters (m): [-3.26697027e+32 -6.12904432e+35 -4.54299085e+33 -1.37503169e+34\n",
            " -1.69015729e+33]\n",
            "Model Parameter (b): -3.266970264133599e+32\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 96, Cost: 5.810620203037528e+77\n",
            "Model Parameters (m): [2.80837595e+32 5.26869214e+35 3.90527776e+33 1.18201442e+34\n",
            " 1.45290490e+33]\n",
            "Model Parameter (b): 2.8083759567396403e+32\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 97, Cost: 4.293807913975441e+77\n",
            "Model Parameters (m): [-2.41415585e+32 -4.52911016e+35 -3.35708226e+33 -1.01609153e+34\n",
            " -1.24895630e+33]\n",
            "Model Parameter (b): -2.4141558501586466e+32\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 98, Cost: 3.1729463908997437e+77\n",
            "Model Parameters (m): [2.07527363e+32 3.89334550e+35 2.88583869e+33 8.73459749e+33\n",
            " 1.07363661e+33]\n",
            "Model Parameter (b): 2.075273637882517e+32\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 99, Cost: 2.344676101312315e+77\n",
            "Model Parameters (m): [-1.78396129e+32 -3.34682502e+35 -2.48074489e+33 -7.50849596e+33\n",
            " -9.22927030e+32]\n",
            "Model Parameter (b): -1.783961283671268e+32\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Iteration 100, Cost: 1.7326186272268665e+77\n",
            "Model Parameters (m): [1.53354135e+32 2.87702124e+35 2.13251540e+33 6.45450617e+33\n",
            " 7.93373036e+32]\n",
            "Model Parameter (b): 1.5335413565644567e+32\n",
            "Learning Rate: 3.0072865982171743e-07\n",
            "\n",
            "Final Model Parameters (m): [1.53354135e+32 2.87702124e+35 2.13251540e+33 6.45450617e+33\n",
            " 7.93373036e+32]\n",
            "Final Model Parameter (b): 1.5335413565644567e+32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h6OEzKgmFJFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hG2Lzp-fPLRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YdUnYOMldLFr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}